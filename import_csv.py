#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excel/CSV æ•°æ®å¯¼å…¥å·¥å…·ï¼ˆè½»é‡ç‰ˆï¼‰
æ— éœ€å®‰è£… pandasï¼Œä½¿ç”¨æ ‡å‡†åº“ csv æ¨¡å—
"""

import csv
import json
import os
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional


def parse_date(date_str: str) -> Optional[str]:
    """è§£æå„ç§æ—¥æœŸæ ¼å¼"""
    if not date_str or not date_str.strip():
        return None
    
    date_str = str(date_str).strip()
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    date_formats = [
        "%Y-%m-%d",
        "%Y/%m/%d",
        "%d/%m/%Y",
        "%d-%m-%Y",
        "%m/%d/%Y",
        "%Yå¹´%mæœˆ%dæ—¥",
        "%Y.%m.%d",
        "%d.%m.%Y"
    ]
    
    for fmt in date_formats:
        try:
            parsed = datetime.strptime(date_str, fmt)
            return parsed.strftime("%Y-%m-%d")
        except:
            continue
    
    # å°è¯• Excel åºåˆ—å·æ ¼å¼ï¼ˆå¦‚ 44500ï¼‰
    try:
        excel_date = int(float(date_str))
        if 1 <= excel_date <= 50000:  # Excel æ—¥æœŸçš„åˆç†èŒƒå›´
            parsed = datetime(1899, 12, 30) + timedelta(days=excel_date)
            return parsed.strftime("%Y-%m-%d")
    except:
        pass
    
    return None


def parse_number(value: str) -> float:
    """è§£ææ•°å­—ï¼Œå¤„ç†å„ç§æ ¼å¼"""
    if not value:
        return 0.0
    
    # ç§»é™¤å¯èƒ½çš„è´§å¸ç¬¦å·å’Œé€—å·
    cleaned = str(value).replace('Â¥', '').replace('å…ƒ', '').replace(',', '').replace(' ', '').strip()
    
    try:
        return float(cleaned)
    except:
        return 0.0


def detect_columns(headers: List[str]) -> Dict[str, int]:
    """
    è‡ªåŠ¨è¯†åˆ«åˆ—ç´¢å¼•
    è¿”å›åˆ—ååˆ°ç´¢å¼•çš„æ˜ å°„
    """
    column_mapping = {}
    headers_lower = [h.lower().strip() for h in headers]
    
    # æ—¥æœŸåˆ—
    date_keywords = ['æ—¥æœŸ', 'date', 'æ—¶é—´', 'time']
    for i, h in enumerate(headers_lower):
        if any(kw in h for kw in date_keywords):
            column_mapping['date'] = i
            break
    
    # æ•°é‡åˆ—
    quantity_keywords = ['æ•°é‡', 'quantity', 'å¥—æ•°', 'ä»¶æ•°', 'å¥—', 'qty']
    for i, h in enumerate(headers_lower):
        if any(kw in h for kw in quantity_keywords):
            column_mapping['quantity'] = i
            break
    
    # å•ä»·åˆ—
    price_keywords = ['å•ä»·', 'price', 'unit', 'ä»·æ ¼', 'å•ä»·(å…ƒ)']
    for i, h in enumerate(headers_lower):
        if any(kw in h for kw in price_keywords):
            column_mapping['unit_price'] = i
            break
    
    # å¤‡æ³¨åˆ—
    note_keywords = ['å¤‡æ³¨', 'note', 'è¯´æ˜', 'æè¿°', 'notes', 'å®¢æˆ·']
    for i, h in enumerate(headers_lower):
        if any(kw in h for kw in note_keywords):
            column_mapping['note'] = i
            break
    
    return column_mapping


def read_csv_file(file_path: str) -> tuple:
    """è¯»å– CSV æ–‡ä»¶"""
    encodings = ['utf-8-sig', 'utf-8', 'gbk', 'gb2312']
    
    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding, newline='') as f:
                # æ£€æµ‹åˆ†éš”ç¬¦
                sample = f.read(2048)
                f.seek(0)
                
                if ',' in sample:
                    reader = csv.reader(f)
                elif '\t' in sample:
                    reader = csv.reader(f, delimiter='\t')
                else:
                    reader = csv.reader(f)
                
                rows = list(reader)
                if rows:
                    return rows[0], rows[1:], encoding  # headers, data, encoding
        except:
            continue
    
    return None, None, None


def import_data(file_path: str, accounting_tool=None) -> Dict:
    """å¯¼å…¥æ•°æ®"""
    print(f"\nğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶: {file_path}")
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return {"success": False, "error": "æ–‡ä»¶ä¸å­˜åœ¨"}
    
    # è¯»å–æ–‡ä»¶
    headers, data_rows, encoding = read_csv_file(file_path)
    
    if headers is None:
        print("âŒ æ— æ³•è¯»å–æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç¼–ç ")
        return {"success": False, "error": "æ— æ³•è¯»å–æ–‡ä»¶"}
    
    print(f"âœ… æˆåŠŸè¯»å–ï¼ˆä½¿ç”¨ {encoding} ç¼–ç ï¼‰")
    print(f"ğŸ“Š å…± {len(data_rows)} è¡Œæ•°æ®")
    
    # æ˜¾ç¤ºåˆ—å
    print(f"\nğŸ“‹ æ£€æµ‹åˆ°ä»¥ä¸‹åˆ—:")
    for i, col in enumerate(headers, 1):
        print(f"   {i}. {col}")
    
    # è‡ªåŠ¨è¯†åˆ«åˆ—
    column_mapping = detect_columns(headers)
    
    print(f"\nğŸ” è‡ªåŠ¨è¯†åˆ«çš„åˆ—:")
    required_cols = {
        'date': 'æ—¥æœŸ',
        'quantity': 'æ•°é‡',
        'unit_price': 'å•ä»·'
    }
    
    for key, name in required_cols.items():
        if key in column_mapping:
            idx = column_mapping[key]
            print(f"   {name}: ç¬¬ {idx + 1} åˆ— ({headers[idx]})")
        else:
            print(f"   {name}: æœªè¯†åˆ« âš ï¸")
    
    # æ‰‹åŠ¨æŒ‡å®šç¼ºå¤±çš„åˆ—
    for key, name in required_cols.items():
        if key not in column_mapping:
            while True:
                try:
                    col_num = input(f"\nè¯·æ‰‹åŠ¨è¾“å…¥'{name}'å¯¹åº”çš„åˆ—å· (1-{len(headers)}): ").strip()
                    idx = int(col_num) - 1
                    if 0 <= idx < len(headers):
                        column_mapping[key] = idx
                        print(f"   âœ… å·²è®¾ç½®: {headers[idx]}")
                        break
                    else:
                        print(f"   âŒ åˆ—å·è¶…å‡ºèŒƒå›´")
                except ValueError:
                    print(f"   âŒ è¯·è¾“å…¥æ•°å­—")
    
    # ç¡®è®¤å¯¼å…¥
    print(f"\nğŸ“Š å³å°†å¯¼å…¥ {len(data_rows)} æ¡è®°å½•")
    confirm = input("ç¡®è®¤å¯¼å…¥? (y/n): ").strip().lower()
    
    if confirm != 'y':
        return {"success": False, "message": "ç”¨æˆ·å–æ¶ˆå¯¼å…¥"}
    
    # å¼€å§‹å¯¼å…¥
    imported_records = []
    failed_records = []
    
    print(f"\nğŸ”„ æ­£åœ¨å¯¼å…¥æ•°æ®...")
    
    for row_idx, row in enumerate(data_rows, start=2):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆç¬¬1è¡Œæ˜¯è¡¨å¤´ï¼‰
        try:
            # æ£€æŸ¥è¡Œæ˜¯å¦æœ‰è¶³å¤Ÿåˆ—
            if len(row) < max(column_mapping.values()) + 1:
                failed_records.append({
                    "row": row_idx,
                    "reason": "åˆ—æ•°ä¸è¶³",
                    "data": row
                })
                continue
            
            # è§£ææ•°æ®
            date_str = parse_date(row[column_mapping['date']])
            if not date_str:
                failed_records.append({
                    "row": row_idx,
                    "reason": f"æ—¥æœŸæ ¼å¼æ— æ³•è¯†åˆ«: {row[column_mapping['date']]}",
                    "data": row
                })
                continue
            
            quantity = parse_number(row[column_mapping['quantity']])
            unit_price = parse_number(row[column_mapping['unit_price']])
            
            if quantity <= 0:
                failed_records.append({
                    "row": row_idx,
                    "reason": f"æ•°é‡æ— æ•ˆ: {quantity}",
                    "data": row
                })
                continue
            
            if unit_price <= 0:
                failed_records.append({
                    "row": row_idx,
                    "reason": f"å•ä»·æ— æ•ˆ: {unit_price}",
                    "data": row
                })
                continue
            
            # å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰
            note = ""
            if 'note' in column_mapping:
                note_val = row[column_mapping['note']]
                if note_val:
                    note = str(note_val).strip()
            
            # åˆ›å»ºè®°å½•
            record = {
                "date": date_str,
                "quantity": int(quantity),
                "unit_price": float(unit_price),
                "total_amount": float(quantity * unit_price),
                "note": note
            }
            
            imported_records.append(record)
            
        except Exception as e:
            failed_records.append({
                "row": row_idx,
                "reason": f"å¤„ç†é”™è¯¯: {str(e)}",
                "data": row
            })
    
    # ä¿å­˜æ•°æ®
    if imported_records:
        if accounting_tool:
            # ç›´æ¥å¯¼å…¥åˆ° accounting_tool
            start_id = len(accounting_tool.records) + 1
            for i, record in enumerate(imported_records):
                record["id"] = start_id + i
                record["created_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                accounting_tool.records.append(record)
            
            accounting_tool._save_records()
        else:
            # ä¿å­˜ä¸ºç‹¬ç«‹çš„å¯¼å…¥æ–‡ä»¶
            output_file = os.path.expanduser("~/.accounting-tool/imported_data.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(imported_records, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    # ä¿å­˜å¤±è´¥è®°å½•æ—¥å¿—
    if failed_records:
        log_file = os.path.expanduser("~/.accounting-tool/import_failed.log")
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write("å¯¼å…¥å¤±è´¥çš„è®°å½•:\n")
            f.write("="*50 + "\n\n")
            for record in failed_records:
                f.write(f"ç¬¬ {record['row']} è¡Œ\n")
                f.write(f"åŸå› : {record['reason']}\n")
                f.write(f"æ•°æ®: {record.get('data', 'N/A')}\n")
                f.write("-"*50 + "\n")
        print(f"ğŸ“ å¤±è´¥è®°å½•æ—¥å¿—: {log_file}")
    
    return {
        "success": True,
        "imported": len(imported_records),
        "failed": len(failed_records),
        "records": imported_records
    }


def merge_imported_data():
    """å°†å¯¼å…¥çš„æ•°æ®åˆå¹¶åˆ°ä¸»è®°å½•ä¸­"""
    import_file = os.path.expanduser("~/.accounting-tool/imported_data.json")
    main_file = os.path.expanduser("~/.accounting-tool/records.json")
    
    if not os.path.exists(import_file):
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯¼å…¥çš„æ•°æ®æ–‡ä»¶")
        return False
    
    # è¯»å–å¯¼å…¥çš„æ•°æ®
    with open(import_file, 'r', encoding='utf-8') as f:
        imported_records = json.load(f)
    
    # è¯»å–ç°æœ‰è®°å½•
    existing_records = []
    if os.path.exists(main_file):
        with open(main_file, 'r', encoding='utf-8') as f:
            existing_records = json.load(f)
    
    # åˆ†é… ID å¹¶æ·»åŠ åˆ›å»ºæ—¶é—´
    start_id = len(existing_records) + 1
    for i, record in enumerate(imported_records):
        record["id"] = start_id + i
        record["created_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # åˆå¹¶
    existing_records.extend(imported_records)
    
    # ä¿å­˜
    with open(main_file, 'w', encoding='utf-8') as f:
        json.dump(existing_records, f, ensure_ascii=False, indent=2)
    
    # åˆ é™¤ä¸´æ—¶å¯¼å…¥æ–‡ä»¶
    os.remove(import_file)
    
    print(f"âœ… æˆåŠŸåˆå¹¶ {len(imported_records)} æ¡è®°å½•")
    return True


def main():
    """ä¸»ç¨‹åº"""
    print("="*60)
    print("ğŸ“¥ Excel/CSV æ•°æ®å¯¼å…¥å·¥å…·")
    print("="*60)
    print("\næ”¯æŒçš„æ–‡ä»¶æ ¼å¼:")
    print("  â€¢ CSV (.csv) - æ¨è")
    print("  â€¢ Excel å¯¼å‡ºä¸º CSV")
    print("\nä½¿ç”¨æ­¥éª¤:")
    print("  1. å°† Excel å¦å­˜ä¸º CSV æ ¼å¼")
    print("  2. è¿è¡Œæ­¤å·¥å…·å¯¼å…¥")
    print("  3. æ£€æŸ¥å¯¼å…¥ç»“æœ")
    print()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¾…åˆå¹¶çš„æ•°æ®
    import_file = os.path.expanduser("~/.accounting-tool/imported_data.json")
    if os.path.exists(import_file):
        print("âš ï¸  æ£€æµ‹åˆ°ä¹‹å‰å¯¼å…¥ä½†æœªåˆå¹¶çš„æ•°æ®")
        merge = input("æ˜¯å¦å…ˆåˆå¹¶ä¹‹å‰çš„æ•°æ®? (y/n): ").strip().lower()
        if merge == 'y':
            if merge_imported_data():
                print("âœ… æ•°æ®åˆå¹¶å®Œæˆ\n")
    
    # è·å–æ–‡ä»¶è·¯å¾„
    file_path = input("è¯·è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„: ").strip()
    file_path = file_path.strip('"').strip("'")
    
    # å¦‚æœåªæœ‰æ–‡ä»¶åï¼Œå°è¯•åœ¨æ¡Œé¢å’Œä¸‹è½½æ–‡ä»¶å¤¹æŸ¥æ‰¾
    if not os.path.dirname(file_path):
        desktop = os.path.expanduser("~/Desktop")
        downloads = os.path.expanduser("~/Downloads")
        
        for folder in [desktop, downloads, os.getcwd()]:
            full_path = os.path.join(folder, file_path)
            if os.path.exists(full_path):
                file_path = full_path
                print(f"   âœ… åœ¨ {folder} æ‰¾åˆ°æ–‡ä»¶")
                break
    
    # å¯¼å…¥æ•°æ®
    result = import_data(file_path)
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "="*60)
    if result["success"]:
        print(f"âœ… å¯¼å…¥å®Œæˆ!")
        print(f"   æˆåŠŸ: {result['imported']} æ¡")
        if result.get('failed', 0) > 0:
            print(f"   å¤±è´¥: {result['failed']} æ¡")
        
        if result['imported'] > 0:
            merge = input("\næ˜¯å¦ç«‹å³åˆå¹¶åˆ°ä¸»è®°è´¦ç³»ç»Ÿ? (y/n): ").strip().lower()
            if merge == 'y':
                if merge_imported_data():
                    print("\nğŸ‰ æ•°æ®å·²æˆåŠŸå¯¼å…¥è®°è´¦ç³»ç»Ÿï¼")
                    print("   ç°åœ¨å¯ä»¥è¿è¡Œ 'python accounting.py' æŸ¥çœ‹")
    else:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {result.get('error', result.get('message', 'æœªçŸ¥é”™è¯¯'))}")
    
    print("="*60)


if __name__ == "__main__":
    main()
